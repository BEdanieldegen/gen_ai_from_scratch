{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source\n",
    "\n",
    "#### https://github.com/karpathy/nn-zero-to-hero/blob/master/lectures/makemore/makemore_part4_backprop.ipynb\n",
    "#### https://www.youtube.com/watch?v=q8SA3rM6ckI&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  torch.set_printoptions(precision=8)\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3275, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1\n",
    "### Find Derivatives through the whole process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 27])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: False | approximate: False | maxdiff: 0.006048846989870071\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: False | approximate: True  | maxdiff: 6.51925802230835e-09\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "bngain          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "bnraw           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "bndiff          | exact: False | approximate: False | maxdiff: 0.0010514119639992714\n",
      "bnvar_inv       | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "bnvar           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "bndiff2         | exact: False | approximate: True  | maxdiff: 2.1827872842550278e-11\n",
      "bndiff          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "hprebn          | exact: False | approximate: False | maxdiff: 0.0010167098371312022\n",
      "bnmeani         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "hprebn          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "embcat          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "W1              | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "b1              | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
      "emb             | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "C               | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n"
     ]
    }
   ],
   "source": [
    "# Manually (own solution)\n",
    "\n",
    "# dy/dx \n",
    "# dloss/dlogprobs\n",
    "# loss = -1 * (a + b + c + ... + k) / n\n",
    "# loss = -1/n*a + -1/n*b + -1/n*c ... + -1/n*k\n",
    "# dloss/da = -1/n\n",
    "# dloss/db = -1/n\n",
    "# ...\n",
    "# \n",
    "dlogprobs =  torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1/n\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "\n",
    "# dloss/dprobs\n",
    "# Local derivative:\n",
    "# dL/dprobs: log(probs)  |  log(x): 1/x\n",
    "# 1/probs\n",
    "# Chainrule:\n",
    "# 1/probs*dlogprobs\n",
    "\n",
    "dprobs = 1/probs * dlogprobs\n",
    "cmp('probs', dprobs, probs)\n",
    "\n",
    "\n",
    "# dloss/dcounts_sum_inv\n",
    "# counts_sum_inv = counts_sum**-1\n",
    "# -1 * counts_sum**-2 * dprobs\n",
    "\n",
    "dcounts_sum_inv = torch.zeros_like(counts_sum_inv)\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "\n",
    "#Can't check here since counce sum inv depends on counts which I'll do later\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "cmp('counts', dcounts, counts)\n",
    "\n",
    "dcounts_sum = -1 *counts_sum**-2 * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "cmp('counts', dcounts, counts)\n",
    "\n",
    "dnorm_logits= norm_logits.exp() * dcounts\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "\n",
    "\n",
    "dlogits = dnorm_logits.clone()\n",
    "cmp('logits', dlogits, logits)\n",
    "\n",
    "\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes= logits.shape[1]) * dlogit_maxes\n",
    "cmp('logits', dlogits, logits)\n",
    "\n",
    "#logits = h @ W2 + b2 # output layer\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "\n",
    "dhpreact = (1-torch.tanh(hpreact)**2) * dh\n",
    "#dhpreact = (1.0-h**2) * dh   # equivalent\n",
    "\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "\n",
    "\n",
    "\n",
    "#hpreact = bngain * bnraw + bnbias\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "\n",
    "dbnraw = bngain * dhpreact\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "#hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "\n",
    "\n",
    "#bndiff2 = bndiff**2\n",
    "#bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "\n",
    "dbndiff = bnvar_inv * dbnraw # noch nicht korrekt: bndiff geht noch in bndiff2 rein\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "\n",
    "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "\n",
    "#dbndiff2 = 1/(n-1) * torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff2 = 1/(n-1)  * dbnvar\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "\n",
    "dbndiff += 2*bndiff * dbndiff2\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "\n",
    "\n",
    "#emb = C[Xb] # embed the characters into vectors\n",
    "#embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "#hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "dhprebn = dbndiff.clone() # something is still missing\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "\n",
    "dbnmeani = -dbndiff.sum(0, keepdim=True)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "\n",
    "dhprebn += torch.ones_like(hprebn) * 1/n * dbnmeani\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "\n",
    "\n",
    "dembcat = dhprebn @ W1.T\n",
    "cmp('embcat', dembcat, embcat)\n",
    "\n",
    "dW1 = embcat.T @ dhprebn\n",
    "cmp('W1', dW1, W1)\n",
    "\n",
    "db1 = dhprebn.sum(0)\n",
    "cmp('b1', db1, b1)\n",
    "\n",
    "\n",
    "#emb = C[Xb] # embed the characters into vectors\n",
    "#embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "demb = dembcat.view(emb.shape) # put back in old shape\n",
    "cmp('emb', demb, emb)\n",
    "\n",
    "dC = torch.zeros_like(C)\n",
    "for i in range(Xb.shape[0]): # iterate over rows: 32\n",
    "    for j in range(Xb.shape[1]): # iterate over columns: 3\n",
    "        ix = Xb[i,j] \n",
    "        dC[ix] += demb[i, j]\n",
    "        #print(i, j)\n",
    "\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.327498197555542 diff: 2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "dlogits = F.softmax(logits, 1)\n",
    "\n",
    "# equivalent\n",
    "dlogits_ = torch.zeros(32,27)\n",
    "for i in range(len(dlogits_)):\n",
    "    for j in range(len(dlogits_[0])):\n",
    "        dlogits_ = logits.exp() / logits.exp().sum(1, keepdims=True)\n",
    "\n",
    "dlogits_[range(n), Yb] -= 1\n",
    "dlogits_ /= n\n",
    "len(dlogits_)\n",
    "\n",
    "#dlogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.05359673500061e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('logits', dlogits_, logits) # I can only get approximate to be true, my maxdiff is 6e-9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison: We push the probility of the correct value to one and pull down the probablities of the incorrect values to be zero\n",
    "#### The gradient is the effect on the loss. Intuitively, the correct value should have a negative effect on the loss (loss is minimized), while the other character should not have any effect at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.98491931e-10,  3.72529030e-09, -1.86264515e-09,  2.32830644e-09,\n",
       "        -1.39698386e-09,  1.16415322e-09,  4.65661287e-09, -1.39698386e-09,\n",
       "        -2.32830644e-09, -4.65661287e-10,  9.31322575e-10,  6.28642738e-09,\n",
       "        -9.31322575e-10, -1.86264515e-09,  4.65661287e-10,  2.32830644e-10,\n",
       "        -1.86264515e-09,  9.31322575e-10,  2.79396772e-09, -2.32830644e-09,\n",
       "         3.25962901e-09,  1.86264515e-09, -9.31322575e-10, -9.31322575e-10,\n",
       "         1.86264515e-09, -1.39698386e-09, -3.72529030e-09,  1.16415322e-09,\n",
       "        -9.31322575e-10,  9.31322575e-10, -1.86264515e-09, -6.98491931e-10],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_.sum(1) # row sums are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.07364131,  0.09282240,  0.01859030,  0.04648277,  0.01682143,\n",
       "         0.08140984,  0.02140707,  0.03431389, -0.98209697,  0.03029753,\n",
       "         0.03898219,  0.03428151,  0.03760144,  0.02904300,  0.03676803,\n",
       "         0.01335267,  0.00859140,  0.01771618,  0.01505357,  0.05499218,\n",
       "         0.05065028,  0.02210714,  0.02505537,  0.07464390,  0.05782820,\n",
       "         0.02815031,  0.02149300], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6b8bd6a260>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits_.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.76837158e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/  20000: 3.8189\n",
      "  10000/  20000: 2.1675\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.2139227390289307\n",
      "val 2.2301344871520996\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mri.\n",
      "almyanziee.\n",
      "med.\n",
      "ryah.\n",
      "rethretted.\n",
      "lei.\n",
      "azeer.\n",
      "melin.\n",
      "shi.\n",
      "jen.\n",
      "eden.\n",
      "estanaraelynnorote.\n",
      "marshebergihiriel.\n",
      "kendreelynn.\n",
      "noraco.\n",
      "uber.\n",
      "cel.\n",
      "kyleni.\n",
      "eli.\n",
      "kaysh.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
