{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron (MLP)\n",
    "# # Based on approach (Bengio et al. 2003): https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\n",
    "# https://www.youtube.com/watch?v=TCH_1BHY58I&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=3\n",
    "# https://github.com/karpathy/nn-zero-to-hero/blob/master/lectures/makemore/makemore_part2_mlp.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    #print(context)\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(f'{context} -> {ix}')\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        #print(context[1:])\n",
    "        #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "        #print(context[1:] +[ix])\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Layer\n",
    "\n",
    " this layer maps input information from a high-dimensional to a lower-dimensional space, allowing the network to learn more about the relationship between inputs and to process the data more efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27, 2))\n",
    "print(C[20:27])\n",
    "print(C[0])\n",
    "print(X[27,2])\n",
    "print(C[X][15])\n",
    "\n",
    "print(C.shape)\n",
    "print(X.shape)\n",
    "print((C[X].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is equivalent to the the weight matrix: so this the first layer of this neural network is just coming from the weight matrix\n",
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[[5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship\n",
    "print(X[14,2])\n",
    "print(C[X][14,2])\n",
    "print(C[22])\n",
    "#print(C[X].shape)\n",
    "print(C[X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn(6, 100) \n",
    "b1 = torch.randn(100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cat([emb[: , 0, :], emb[: , 1, :], emb[: , 2, :]], dim=1).shape)\n",
    "torch.cat([emb[: , 0, :], emb[: , 1, :], emb[: , 2, :]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more efficent: idependent of number of emb\n",
    "torch.cat(torch.unbind(emb, 1),1).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even more efficient\n",
    "a = torch.arange(18)\n",
    "a\n",
    "\n",
    "print(a.view(9,2))\n",
    "print(a.view(9,2))\n",
    "print(a.view(3,3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.view(32,6) == torch.cat(torch.unbind(emb, 1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((emb.view(emb.shape[0],6) @ W1 + b1).shape)\n",
    "print(emb.view(emb.shape[0],6) @ W1 + b1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.tanh(emb.view(emb.shape[0],6) @ W1 + b1)  # tanh: -1 until +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn(100, 27)\n",
    "b2 = torch.randn(27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2\n",
    "logits.shape\n",
    "\n",
    "# Softmax\n",
    "counts = logits.exp()  # equivalent to N matrix from above\n",
    "prob = counts / counts.sum(1, keepdims=True)  #normalized counts to probabilities\n",
    "print(prob.shape)\n",
    "print(prob[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-prob[torch.arange(32), Y].log().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Comprehensive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix]\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn(6, 100, generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb = C[X]\n",
    "#h = torch.tanh(emb.view(emb.shape[0],6) @ W1 + b1)  # tanh: -1 until +1\n",
    "#logits = h @ W2 + b2\n",
    "#counts = logits.exp()  # equivalent to N matrix from above\n",
    "#prob = counts / counts.sum(1, keepdims=True)  #normalized counts to probabilities\n",
    "\n",
    "#loss1 = -prob[torch.arange(32), Y].log().mean()\n",
    "#print(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X]\n",
    "h = torch.tanh(emb.view(emb.shape[0],6) @ W1 + b1)  # tanh: -1 until +1\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y)  # equivalent, but much more efficient. + logits.exp() can produce values up to infinity; F.cross_entropy substracts the maximum value internally and solves this problem\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "    \n",
    "for _ in range(1000):\n",
    "\n",
    "    # Forward Pass\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(emb.shape[0],6) @ W1 + b1) \n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y)  \n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward Pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix]\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn(6, 100, generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "    \n",
    "for _ in range(100):\n",
    "\n",
    "    # Forward Pass\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(emb.shape[0],6) @ W1 + b1) \n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y)  \n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward Pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to determine Learning Rate parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn(6, 100, generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix]\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "lre = torch.linspace(-3,0, 1000)\n",
    "lrs = 10**lre\n",
    "print(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add multiple minibatches\n",
    "gix = torch.Generator().manual_seed(2147483647)\n",
    "lri = []\n",
    "losses = []\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "    \n",
    "for i in range(1000):\n",
    "    \n",
    "    # Construct Minibatch of 128 Names\n",
    "    ix = torch.randint(0, X.shape[0], (128,), generator=gix)  # here also a seed should be set\n",
    "\n",
    "    # Forward Pass\n",
    "    emb = C[X[ix]]\n",
    "    h = torch.tanh(emb.view(emb.shape[0],6) @ W1 + b1) \n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y[ix])  \n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward Pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    lr = lrs[i]\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    # Track Learning Rate and Loss\n",
    "    lri.append(lre[i])\n",
    "    losses.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lri, losses) # Learning Rate around 10**-1 = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Train, Def/Validation, and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    block_size = 3\n",
    "\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "X_train , Y_train = build_dataset(words[:n1])\n",
    "X_val, Y_val = build_dataset(words[n1:n2])\n",
    "X_test, Y_test = build_dataset(words[n2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2147483647\n",
    "\n",
    "g = torch.Generator().manual_seed(seed)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn(6, 300, generator=g)\n",
    "b1 = torch.randn(300, generator=g)\n",
    "W2 = torch.randn((300, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "\n",
    " \n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add multiple minibatches\n",
    "steps=[]\n",
    "losses=[]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "    \n",
    "for i in range(1000):\n",
    "    \n",
    "    gix = torch.Generator().manual_seed(seed)\n",
    "    # Construct Minibatch of 128 Names\n",
    "    ix = torch.randint(0, X_train.shape[0], (128,), generator = gix)\n",
    "    seed += 1\n",
    "    \n",
    "    # Forward Pass\n",
    "    emb = C[X_train[ix]]\n",
    "    h = torch.tanh(emb.view(emb.shape[0],6) @ W1 + b1) \n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y_train[ix])  \n",
    "    \n",
    "    # Backward Pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    # Stats\n",
    "    steps.append(i)\n",
    "    losses.append(loss.item())\n",
    "#print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(steps, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X_train]  \n",
    "h = torch.tanh(emb.view(emb.shape[0],6) @ W1 + b1) \n",
    "logits = h @ W2 + b2\n",
    "loss_dev = F.cross_entropy(logits, Y_train) \n",
    "loss_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X_val]  \n",
    "h = torch.tanh(emb.view(emb.shape[0],6) @ W1 + b1) \n",
    "logits = h @ W2 + b2\n",
    "loss_dev = F.cross_entropy(logits, Y_val) \n",
    "loss_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize dimensions 0 and 1 of the embedding matrix C for all characters\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
    "plt.grid('minor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increase Imeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    block_size = 3\n",
    "\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "X_train , Y_train = build_dataset(words[:n1])\n",
    "X_val, Y_val = build_dataset(words[n1:n2])\n",
    "X_test, Y_test = build_dataset(words[n2:])\n",
    "\n",
    "\n",
    "\n",
    "seed = 2147483647\n",
    "\n",
    "g = torch.Generator().manual_seed(seed)\n",
    "C = torch.randn((27, 20), generator=g)\n",
    "W1 = torch.randn(60, 500, generator=g)\n",
    "b1 = torch.randn(500, generator=g)\n",
    "W2 = torch.randn((500, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "\n",
    " \n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "# Add multiple minibatches\n",
    "steps=[]\n",
    "losses=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "    \n",
    "for i in range(100000):\n",
    "    \n",
    "    gix = torch.Generator().manual_seed(seed)\n",
    "    # Construct Minibatch of 128 Names\n",
    "    ix = torch.randint(0, X_train.shape[0], (512,), generator = gix)\n",
    "    seed += 1\n",
    "    \n",
    "    # Forward Pass\n",
    "    emb = C[X_train[ix]]\n",
    "    h = torch.tanh(emb.view(emb.shape[0],60) @ W1 + b1) \n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y_train[ix])  \n",
    "    \n",
    "    # Backward Pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    # Stats\n",
    "\n",
    "    steps.append(i)\n",
    "    losses.append(loss.log10().item())\n",
    "    #print(len(steps),len(losses))\n",
    "#print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(steps), len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd5d51ed300>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(steps, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9943, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X_train]  \n",
    "h = torch.tanh(emb.view(emb.shape[0],60) @ W1 + b1) \n",
    "logits = h @ W2 + b2\n",
    "loss_dev = F.cross_entropy(logits, Y_train) \n",
    "loss_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3039, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X_test]  \n",
    "h = torch.tanh(emb.view(emb.shape[0],60) @ W1 + b1) \n",
    "logits = h @ W2 + b2\n",
    "loss_dev = F.cross_entropy(logits, Y_test) \n",
    "loss_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naitana.\n",
      "emma.\n",
      "ziya.\n",
      "bron.\n",
      "kalen.\n",
      "lei.\n",
      "jamarah.\n",
      "lyler.\n",
      "mar.\n",
      "embere.\n",
      "rayden.\n",
      "marion.\n",
      "wiselistie.\n",
      "meraj.\n",
      "killa.\n",
      "shine.\n",
      "zaryan.\n",
      "masey.\n",
      "cyn.\n",
      "nen.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 1000)\n",
    "block_size = 3\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "      logits = h @ W2 + b2\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add another layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_genai",
   "language": "python",
   "name": "venv_genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
