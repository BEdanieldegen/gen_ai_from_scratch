{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on approach (Bengio et al. 2003): https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\n",
    "# https://www.youtube.com/watch?v=TCH_1BHY58I&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=3\n",
    "# https://github.com/karpathy/nn-zero-to-hero/blob/master/lectures/makemore/makemore_part2_mlp.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchimport'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchimport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchimport'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchimport.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "[0, 0, 0] -> 5\n",
      "... ---> e\n",
      "[0, 0, 5] -> 13\n",
      "..e ---> m\n",
      "[0, 5, 13] -> 13\n",
      ".em ---> m\n",
      "[5, 13, 13] -> 1\n",
      "emm ---> a\n",
      "[13, 13, 1] -> 0\n",
      "mma ---> .\n",
      "olivia\n",
      "[0, 0, 0] -> 15\n",
      "... ---> o\n",
      "[0, 0, 15] -> 12\n",
      "..o ---> l\n",
      "[0, 15, 12] -> 9\n",
      ".ol ---> i\n",
      "[15, 12, 9] -> 22\n",
      "oli ---> v\n",
      "[12, 9, 22] -> 9\n",
      "liv ---> i\n",
      "[9, 22, 9] -> 1\n",
      "ivi ---> a\n",
      "[22, 9, 1] -> 0\n",
      "via ---> .\n",
      "ava\n",
      "[0, 0, 0] -> 1\n",
      "... ---> a\n",
      "[0, 0, 1] -> 22\n",
      "..a ---> v\n",
      "[0, 1, 22] -> 1\n",
      ".av ---> a\n",
      "[1, 22, 1] -> 0\n",
      "ava ---> .\n",
      "isabella\n",
      "[0, 0, 0] -> 9\n",
      "... ---> i\n",
      "[0, 0, 9] -> 19\n",
      "..i ---> s\n",
      "[0, 9, 19] -> 1\n",
      ".is ---> a\n",
      "[9, 19, 1] -> 2\n",
      "isa ---> b\n",
      "[19, 1, 2] -> 5\n",
      "sab ---> e\n",
      "[1, 2, 5] -> 12\n",
      "abe ---> l\n",
      "[2, 5, 12] -> 12\n",
      "bel ---> l\n",
      "[5, 12, 12] -> 1\n",
      "ell ---> a\n",
      "[12, 12, 1] -> 0\n",
      "lla ---> .\n",
      "sophia\n",
      "[0, 0, 0] -> 19\n",
      "... ---> s\n",
      "[0, 0, 19] -> 15\n",
      "..s ---> o\n",
      "[0, 19, 15] -> 16\n",
      ".so ---> p\n",
      "[19, 15, 16] -> 8\n",
      "sop ---> h\n",
      "[15, 16, 8] -> 9\n",
      "oph ---> i\n",
      "[16, 8, 9] -> 1\n",
      "phi ---> a\n",
      "[8, 9, 1] -> 0\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    #print(context)\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(f'{context} -> {ix}')\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        #print(context[1:])\n",
    "        #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "        #print(context[1:] +[ix])\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Layer\n",
    "\n",
    " this layer maps input information from a high-dimensional to a lower-dimensional space, allowing the network to learn more about the relationship between inputs and to process the data more efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2616, -0.0503],\n",
      "        [-0.2191, -0.4354],\n",
      "        [-0.3363, -0.4877],\n",
      "        [-0.8615,  0.1147],\n",
      "        [-0.5297, -0.0669],\n",
      "        [-0.2296,  1.0385],\n",
      "        [-0.4185,  0.4184]])\n",
      "tensor([-1.2616, -0.0503])\n",
      "tensor(0)\n",
      "tensor([[-1.2616, -0.0503],\n",
      "        [-1.2616, -0.0503],\n",
      "        [-1.2616, -0.0503]])\n",
      "torch.Size([27, 2])\n",
      "torch.Size([32, 3])\n",
      "torch.Size([32, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "C = torch.randn((27, 2))\n",
    "print(C[0:7])\n",
    "print(C[0])\n",
    "print(X[1,1])\n",
    "print(C[X][0])\n",
    "\n",
    "print(C.shape)\n",
    "print(X.shape)\n",
    "print((C[X].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2345, 0.8466])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2345, 0.8466])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is equivalent to the the weight matrix: so this the first layer of this neural network is just coming from the weight matrix\n",
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2345,  0.8466],\n",
       "        [-1.2702, -1.2004],\n",
       "        [ 1.1469, -0.3221]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[[5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22)\n",
      "tensor([-0.1551,  0.5959])\n",
      "tensor([-0.1551,  0.5959])\n"
     ]
    }
   ],
   "source": [
    "# Relationship\n",
    "print(X[14,2])\n",
    "print(C[X][14,2])\n",
    "print(C[22])\n",
    "#print(C[X].shape)\n",
    "#print(C[X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630],\n",
       "         [ 0.2345,  0.8466]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.2345,  0.8466],\n",
       "         [ 2.9611,  0.3322]],\n",
       "\n",
       "        [[ 0.2345,  0.8466],\n",
       "         [ 2.9611,  0.3322],\n",
       "         [ 2.9611,  0.3322]],\n",
       "\n",
       "        [[ 2.9611,  0.3322],\n",
       "         [ 2.9611,  0.3322],\n",
       "         [ 0.0989,  0.3924]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630],\n",
       "         [-0.5825,  1.0956]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [-0.5825,  1.0956],\n",
       "         [-0.7490,  0.1247]],\n",
       "\n",
       "        [[-0.5825,  1.0956],\n",
       "         [-0.7490,  0.1247],\n",
       "         [ 1.3228,  1.9427]],\n",
       "\n",
       "        [[-0.7490,  0.1247],\n",
       "         [ 1.3228,  1.9427],\n",
       "         [-0.3794,  0.3068]],\n",
       "\n",
       "        [[ 1.3228,  1.9427],\n",
       "         [-0.3794,  0.3068],\n",
       "         [ 1.3228,  1.9427]],\n",
       "\n",
       "        [[-0.3794,  0.3068],\n",
       "         [ 1.3228,  1.9427],\n",
       "         [ 0.0989,  0.3924]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630],\n",
       "         [ 0.0989,  0.3924]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.0989,  0.3924],\n",
       "         [-0.3794,  0.3068]],\n",
       "\n",
       "        [[ 0.0989,  0.3924],\n",
       "         [-0.3794,  0.3068],\n",
       "         [ 0.0989,  0.3924]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630],\n",
       "         [ 1.3228,  1.9427]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 1.3228,  1.9427],\n",
       "         [ 0.0147, -1.0081]],\n",
       "\n",
       "        [[ 1.3228,  1.9427],\n",
       "         [ 0.0147, -1.0081],\n",
       "         [ 0.0989,  0.3924]],\n",
       "\n",
       "        [[ 0.0147, -1.0081],\n",
       "         [ 0.0989,  0.3924],\n",
       "         [-0.4433, -0.2080]],\n",
       "\n",
       "        [[ 0.0989,  0.3924],\n",
       "         [-0.4433, -0.2080],\n",
       "         [ 0.2345,  0.8466]],\n",
       "\n",
       "        [[-0.4433, -0.2080],\n",
       "         [ 0.2345,  0.8466],\n",
       "         [-0.7490,  0.1247]],\n",
       "\n",
       "        [[ 0.2345,  0.8466],\n",
       "         [-0.7490,  0.1247],\n",
       "         [-0.7490,  0.1247]],\n",
       "\n",
       "        [[-0.7490,  0.1247],\n",
       "         [-0.7490,  0.1247],\n",
       "         [ 0.0989,  0.3924]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.6076,  1.7630],\n",
       "         [ 0.0147, -1.0081]],\n",
       "\n",
       "        [[ 0.6076,  1.7630],\n",
       "         [ 0.0147, -1.0081],\n",
       "         [-0.5825,  1.0956]],\n",
       "\n",
       "        [[ 0.0147, -1.0081],\n",
       "         [-0.5825,  1.0956],\n",
       "         [-0.0094,  0.4913]],\n",
       "\n",
       "        [[-0.5825,  1.0956],\n",
       "         [-0.0094,  0.4913],\n",
       "         [ 1.1737, -0.3905]],\n",
       "\n",
       "        [[-0.0094,  0.4913],\n",
       "         [ 1.1737, -0.3905],\n",
       "         [ 1.3228,  1.9427]],\n",
       "\n",
       "        [[ 1.1737, -0.3905],\n",
       "         [ 1.3228,  1.9427],\n",
       "         [ 0.0989,  0.3924]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn(6, 100) \n",
    "b1 = torch.randn(100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6076,  1.7630,  0.6076,  1.7630,  0.6076,  1.7630],\n",
       "        [ 0.6076,  1.7630,  0.6076,  1.7630,  0.2345,  0.8466],\n",
       "        [ 0.6076,  1.7630,  0.2345,  0.8466,  2.9611,  0.3322],\n",
       "        [ 0.2345,  0.8466,  2.9611,  0.3322,  2.9611,  0.3322],\n",
       "        [ 2.9611,  0.3322,  2.9611,  0.3322,  0.0989,  0.3924],\n",
       "        [ 0.6076,  1.7630,  0.6076,  1.7630,  0.6076,  1.7630],\n",
       "        [ 0.6076,  1.7630,  0.6076,  1.7630, -0.5825,  1.0956],\n",
       "        [ 0.6076,  1.7630, -0.5825,  1.0956, -0.7490,  0.1247],\n",
       "        [-0.5825,  1.0956, -0.7490,  0.1247,  1.3228,  1.9427],\n",
       "        [-0.7490,  0.1247,  1.3228,  1.9427, -0.3794,  0.3068],\n",
       "        [ 1.3228,  1.9427, -0.3794,  0.3068,  1.3228,  1.9427],\n",
       "        [-0.3794,  0.3068,  1.3228,  1.9427,  0.0989,  0.3924],\n",
       "        [ 0.6076,  1.7630,  0.6076,  1.7630,  0.6076,  1.7630],\n",
       "        [ 0.6076,  1.7630,  0.6076,  1.7630,  0.0989,  0.3924],\n",
       "        [ 0.6076,  1.7630,  0.0989,  0.3924, -0.3794,  0.3068],\n",
       "        [ 0.0989,  0.3924, -0.3794,  0.3068,  0.0989,  0.3924],\n",
       "        [ 0.6076,  1.7630,  0.6076,  1.7630,  0.6076,  1.7630],\n",
       "        [ 0.6076,  1.7630,  0.6076,  1.7630,  1.3228,  1.9427],\n",
       "        [ 0.6076,  1.7630,  1.3228,  1.9427,  0.0147, -1.0081],\n",
       "        [ 1.3228,  1.9427,  0.0147, -1.0081,  0.0989,  0.3924],\n",
       "        [ 0.0147, -1.0081,  0.0989,  0.3924, -0.4433, -0.2080],\n",
       "        [ 0.0989,  0.3924, -0.4433, -0.2080,  0.2345,  0.8466],\n",
       "        [-0.4433, -0.2080,  0.2345,  0.8466, -0.7490,  0.1247],\n",
       "        [ 0.2345,  0.8466, -0.7490,  0.1247, -0.7490,  0.1247],\n",
       "        [-0.7490,  0.1247, -0.7490,  0.1247,  0.0989,  0.3924],\n",
       "        [ 0.6076,  1.7630,  0.6076,  1.7630,  0.6076,  1.7630],\n",
       "        [ 0.6076,  1.7630,  0.6076,  1.7630,  0.0147, -1.0081],\n",
       "        [ 0.6076,  1.7630,  0.0147, -1.0081, -0.5825,  1.0956],\n",
       "        [ 0.0147, -1.0081, -0.5825,  1.0956, -0.0094,  0.4913],\n",
       "        [-0.5825,  1.0956, -0.0094,  0.4913,  1.1737, -0.3905],\n",
       "        [-0.0094,  0.4913,  1.1737, -0.3905,  1.3228,  1.9427],\n",
       "        [ 1.1737, -0.3905,  1.3228,  1.9427,  0.0989,  0.3924]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cat([emb[: , 0, :], emb[: , 1, :], emb[: , 2, :]], dim=1).shape)\n",
    "torch.cat([emb[: , 0, :], emb[: , 1, :], emb[: , 2, :]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, 1),1).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_genai",
   "language": "python",
   "name": "venv_genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
